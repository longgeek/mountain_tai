#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Author: Frazy <baoyiluo@gmail.com>

import os
import sys
import logging
os.environ.setdefault("DJANGO_SETTINGS_MODULE",
                      "mountain_tai.config")
from django.core.wsgi import get_wsgi_application
application = get_wsgi_application()
import pika
import uuid
import multiprocessing
import threading
import simplejson as json
from mountain_tai.lib import api
import ConfigParser

CONFIG_FILE = '/etc/mountain/mountain.conf'  # config file


class Send(object):
    """控制中心类"""

    def __init__(self):
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(host=MQ_HOST))

        self.channel = self.connection.channel()

        # 定义接收返回消息的队列
        result = self.channel.queue_declare(exclusive=True)
        self.callback_queue = result.method.queue

        # 定义接收返回消息的队列
        self.channel.basic_consume(self.on_response,
                                   no_ack=False,
                                   queue=self.callback_queue)
        self.response = {}
        pass

    # 定义接收到返回消息的处理方法
    def on_response(self, channel, method, props, body):
        logger.info('Receive from bat: %s' % body)
        updatestatus = api.updatedockerdb(body, PROTOCOL, SERVER_NAME)
        self.response[props.correlation_id] = json.dumps(updatestatus)

    def request(self, body):
        logger.info('Send to bat: %s' % body)
        corr_id = str(uuid.uuid4())
        self.response[corr_id] = None

        # 发送计算请求，并设定返回队列和correlation_id
        self.channel.basic_publish(exchange='',
                                   routing_key=body.get("host"),
                                   properties=pika.BasicProperties(
                                       reply_to=self.callback_queue,
                                       correlation_id=corr_id,
                                   ),
                                   body=json.dumps(body))

        while self.response[corr_id] is None:
            self.connection.process_data_events()
        return self.response[corr_id]


class Center(object):
    """控制中心类"""
    def __init__(self):

        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(host=MQ_HOST))

        self.channel = self.connection.channel()

        # 定义接收返回消息的队列
        self.channel.queue_declare(queue=QUEUE_DOCKER_SCHEDULER,
                                   durable=True)
        self.channel.basic_qos(prefetch_count=1)

        self.channel.basic_consume(self.on_response,
                                   no_ack=False,
                                   queue=QUEUE_DOCKER_SCHEDULER)

    def start(self):
        self.channel.start_consuming()

    # 定义接收到返回消息的处理方法
    def on_response(self, ch, method, props, body):
        """
            1. 先给 docker_task 发送消息
            2. 然后给docker_scheduler返回消息
        """
        send = Send()
        logger.info('Come from restful: %s' % body)
        resultdic = api.scheduler_docker(body)
        if resultdic[0] == 0:
            response = send.request(resultdic[2])
        else:
            response = json.dumps(resultdic)

        ch.basic_publish(exchange='',
                         routing_key=props.reply_to,
                         properties=pika.BasicProperties(
                             correlation_id=props.correlation_id,
                         ),
                         body=response)
        ch.basic_ack(delivery_tag=method.delivery_tag)


class MyThread(threading.Thread):
    """自定义线程类，继承threading.Thread"""

    def __init__(self, func):
        super(MyThread, self).__init__()
        self.func = func

    def run(self):
        self.func()


if __name__ == "__main__":

    try:
        config = ConfigParser.ConfigParser()
        cfgfile = open(CONFIG_FILE, 'r')
        config.readfp(cfgfile)
        LOG_LEVEL = config.get('mountain', 'LOG_LEVEL')
        LOG_FILE = config.get('mountain', 'LOG_FILE')
        MQ_HOST = config.get('mountain', 'MQ_HOST')
        MQ_PORT = int(config.get('mountain', 'MQ_PORT'))
        QUEUE_DOCKER_SCHEDULER = config.get('mountain',
                                            'QUEUE_DOCKER_SCHEDULER')
        QUEUE_DOCKER_TASK = config.get('mountain', 'QUEUE_DOCKER_TASK')
        PROTOCOL = config.get('mountain', 'PROTOCOL')
        SERVER_NAME = config.get('mountain', 'SERVER_NAME')
        WORKERS = int(config.get('mountain', 'WORKERS'))
        PROCESS_PER_WORKER = int(config.get('mountain', 'PROCESS_PRE_WORKER'))
    except Exception, e:
        print e
        print "Can not find config file: %s" % (CONFIG_FILE)
        sys.exit(1)
    fh = logging.FileHandler(LOG_FILE)
    formatter = logging.Formatter(
        '[%(asctime)s][%(name)s][%(levelname)s]: %(message)s')
    fh.setFormatter(formatter)
    logger = logging.getLogger('mountain-scheduler')
    logger.setLevel(getattr(logging, LOG_LEVEL))
    logger.addHandler(fh)

    def run():
        center = Center()
        center.start()

        # threads = []
        # for i in range(PROCESS_PER_WORKER):
        #     mythread = MyThread(center.start)
        #     print 'Process: ', os.getpid(), 'thread = ', mythread
        #     threads.append(mythread)
        # for thread in threads:
        #     thread.start()
        # for thread in threads:
        #     thread.join()

    for i in range(WORKERS):

        p = multiprocessing.Process(target=run)
        p.start()
        logger.info('i = %d process id = %s' % (i, p.pid))
    # center.channel.start_consuming()
